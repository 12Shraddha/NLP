{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package porter_test to\n",
      "[nltk_data]     /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package porter_test is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('porter_test')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.', 'CNNs are regularized versions of multilayer perceptrons.', 'Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer.', 'The \"fully-connectedness\" of these networks makes them prone to overfitting data.', 'Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function.', 'CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns.', 'Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.', 'Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex.', 'Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field.', 'The receptive fields of different neurons partially overlap such that they cover the entire visual field.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize , word_tokenize\n",
    "\n",
    "para = \"\"\"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery.They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.\n",
    "\n",
    "CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"fully-connectedness\" of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\n",
    "\n",
    "Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(para)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In deep learning , convolutional neural network ( CNN , ConvNet ) class deep neural networks , commonly applied analyzing visual imagery.They also known shift invariant space invariant artificial neural networks ( SIANN ) , based shared-weights architecture translation invariance characteristics.They applications image video recognition , recommender systems , image classification , medical image analysis , natural language processing , financial time series . ',\n",
       " 'CNNs regularized versions multilayer perceptrons . ',\n",
       " 'Multilayer perceptrons usually mean fully connected networks , , neuron one layer connected neurons next layer . ',\n",
       " \"The `` fully-connectedness '' networks makes prone overfitting data . \",\n",
       " 'Typical ways regularization include adding form magnitude measurement weights loss function . ',\n",
       " 'CNNs take different approach towards regularization : take advantage hierarchical pattern data assemble complex patterns using smaller simpler patterns . ',\n",
       " 'Therefore , scale connectedness complexity , CNNs lower extreme . ',\n",
       " 'Convolutional networks inspired biological processes connectivity pattern neurons resembles organization animal visual cortex . ',\n",
       " 'Individual cortical neurons respond stimuli restricted region visual field known receptive field . ',\n",
       " 'The receptive fields different neurons partially overlap cover entire visual field . ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "words_array = []\n",
    "for sentence in sentences:\n",
    "    words_array.append(word_tokenize(sentence))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentences = []\n",
    "\n",
    "for words in words_array:\n",
    "    filtered_sentence = ''\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence += w + ' '\n",
    "    filtered_sentences.append(filtered_sentence)\n",
    "\n",
    "filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhiteSpace : ['CNNs', 'are', 'regularized', 'versions', 'of', 'multilayer', 'perceptrons.']\n",
      "7\n",
      "WordPunt : ['CNNs', 'are', 'regularized', 'versions', 'of', 'multilayer', 'perceptrons', '.']\n",
      "8\n",
      "TreeBank : ['CNNs', 'are', 'regularized', 'versions', 'of', 'multilayer', 'perceptrons', '.']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer,WordPunctTokenizer,TreebankWordTokenizer\n",
    "tk1 = WhitespaceTokenizer()\n",
    "wst_sent = tk1.tokenize(sentences[1])\n",
    "print('WhiteSpace :', wst_sent)\n",
    "print(len(wst_sent))\n",
    "\n",
    "tk2 = WordPunctTokenizer()\n",
    "wp_sent = tk2.tokenize(sentences[1])\n",
    "print('WordPunt :', wp_sent)\n",
    "print(len(wp_sent))\n",
    "\n",
    "tk3 = TreebankWordTokenizer()\n",
    "tb_sent = tk3.tokenize(sentences[1])\n",
    "print('TreeBank :',tb_sent)\n",
    "print(len(tb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNNs', 'regularized', 'versions', 'multilayer', 'perceptrons', '.'] \n",
      " 6\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_sentence = [ word for word in tb_sent if word not in stop_words]\n",
    "print(filtered_sentence,'\\n',len(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cnn', 'regular', 'version', 'multilay', 'perceptron', '.'] \n",
      " ['CNNs', 'regularized', 'version', 'multilayer', 'perceptrons', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "stemmed = []\n",
    "lemmatized = []\n",
    "\n",
    "for word in filtered_sentence:\n",
    "    stemmed.append(ps.stem(word))\n",
    "    lemmatized.append(wnl.lemmatize(word))\n",
    "\n",
    "print(stemmed,'\\n',lemmatized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
